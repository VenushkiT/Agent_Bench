{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9abeb0cd-4623-4cb2-bbeb-8249adb64084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cd18e7-4a27-47d0-8834-5abc13db020e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1fef6f-c676-40f2-b616-389810133a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.54.3\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "print(openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acd695c-3ede-4e8d-906f-3c577be186e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "319d0ed6-fb22-44a8-ba61-dc7cd9dd6920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the OpenAI library to interact with the OpenAI API.\n",
    "from openai import OpenAI\n",
    "import textwrap\n",
    "import requests  # used to download images\n",
    "import os  # used to access filepaths\n",
    "from PIL import Image  # used to print and edit images\n",
    "import base64\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image, clear_output\n",
    "import pandas as pd  # To read and handle the CSV file\n",
    "import openai  # To use GPT-4 for evaluation\n",
    "import logging  # For logging results and errors\n",
    "from PIL import Image  # To handle images (Pillow)\n",
    "import logging\n",
    "import csv\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "api_key = \"sk-svcacct-vdeZ2LdFD4WLSoWokO9JpnArMctwcXj1PFex5qsr-zPmffZrs9yG6AbZI4eJHSYbdST3BlbkFJkyirN41YuhOaTHPV2o-VPmd4Ydj_K28bTn6gvV2MfIci_04uGe2tprRE-yWbRxoWUA\"\n",
    "client = OpenAI(api_key=api_key)\n",
    "#judgeGPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd810753-a944-4578-9fdc-dce83dd5090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_smmu_tasks(csv_file_path, images_folder_path):\n",
    "    # Load the CSV data into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Ensure image folder path exists\n",
    "    if not os.path.exists(images_folder_path):\n",
    "        raise FileNotFoundError(f\"The images folder '{images_folder_path}' does not exist.\")\n",
    "    \n",
    "    # Add the image file path to each task by constructing it from the Image_ID column\n",
    "    def add_image_path(row):\n",
    "        image_filename = row['Image_ID']  # Image filename should already include the extension, e.g., 'image_1.jpg'\n",
    "        image_path = os.path.join(images_folder_path, image_filename)\n",
    "        return image_path\n",
    "    \n",
    "    # Apply the function to add the image path to the DataFrame\n",
    "    df['image_path'] = df.apply(add_image_path, axis=1)\n",
    "    df['task_id'] = [f\"task_{i+1}\" for i in range(len(df))]\n",
    "    \n",
    "    # Convert to list of dictionaries for easy use in your loop\n",
    "    tasks = df.to_dict(orient=\"records\")\n",
    "    return tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33fec4f1-7348-408b-ae42-a233b31cf06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_1:\n",
      "  Image Path  : ./ocr_images/image_1.jpg\n",
      "  Question    : What is the level of the Chinese language textbook depicted in the image?\n",
      "  Answer      : The level of the Chinese language textbook depicted in the image is Level 3, as indicated by the number \"3\" on the bottom right-hand side of the cover.\n",
      "----------------------------------------\n",
      "task_2:\n",
      "  Image Path  : ./ocr_images/image_1.jpg\n",
      "  Question    : How many people are shown on the textbook cover?\n",
      "  Answer      : There are five people shown on the textbook cover, with three individuals prominently in the foreground and two in the background.\n",
      "----------------------------------------\n",
      "task_3:\n",
      "  Image Path  : ./ocr_images/image_1.jpg\n",
      "  Question    : What is the predominant color of the textbook's logo at the bottom of the image?\n",
      "  Answer      : The predominant color of the textbook's logo at the bottom of the image is blue.\n",
      "----------------------------------------\n",
      "task_4:\n",
      "  Image Path  : ./ocr_images/image_1.jpg\n",
      "  Question    : Which animal print is visible on the clothing of one of the characters in the image?\n",
      "  Answer      : A tiger print is visible on the clothing of one of the characters, specifically on the shirt of the boy in the foreground to the right.\n",
      "----------------------------------------\n",
      "task_5:\n",
      "  Image Path  : ./ocr_images/image_1.jpg\n",
      "  Question    : What is the primary activity of the person in the wheelchair in the background?\n",
      "  Answer      : The primary activity of the person in the wheelchair in the background appears to be pointing at something.\n",
      "----------------------------------------\n",
      "task_6:\n",
      "  Image Path  : ./ocr_images/image_3.jpg\n",
      "  Question    : What is the page number where the section titled \"亲情世界\" starts?\n",
      "  Answer      : The section titled \"亲情世界\" starts on page 48 as shown in the right column on the upper half of the image.\n",
      "----------------------------------------\n",
      "task_7:\n",
      "  Image Path  : ./ocr_images/image_3.jpg\n",
      "  Question    : Which section's starting page number is directly below the image of two children playing with a plant?\n",
      "  Answer      : The section's starting page number that is directly below the image of two children playing with a plant is for \"爷爷奶奶,\" which begins on page 46.\n",
      "----------------------------------------\n",
      "task_8:\n",
      "  Image Path  : ./ocr_images/image_3.jpg\n",
      "  Question    : On what page does the \"爸爸\" section begin in the upper half of the image?\n",
      "  Answer      : The section titled \"爸爸\" in the upper half of the image begins on page 45.\n",
      "----------------------------------------\n",
      "task_9:\n",
      "  Image Path  : ./ocr_images/image_3.jpg\n",
      "  Question    : What is the last section title listed in the lower half of the image?\n",
      "  Answer      : The last section title listed in the lower half of the image is \"文化传承,\" which starts on page 63.\n",
      "----------------------------------------\n",
      "task_10:\n",
      "  Image Path  : ./ocr_images/image_3.jpg\n",
      "  Question    : Which section has the starting page number 40 in the upper half of the image?\n",
      "  Answer      : The section titled \"妈妈\" has the starting page number 40 in the upper half of the image.\n",
      "----------------------------------------\n",
      "task_11:\n",
      "  Image Path  : ./ocr_images/image_5.jpg\n",
      "  Question    : In the image, where is the sun located?\n",
      "  Answer      : The sun is located near the horizon within the phone’s screen.\n",
      "----------------------------------------\n",
      "task_12:\n",
      "  Image Path  : ./ocr_images/image_5.jpg\n",
      "  Question    : What are the two people in the image doing?\n",
      "  Answer      : The two people in the image appear to be holding hands.\n",
      "----------------------------------------\n",
      "task_13:\n",
      "  Image Path  : ./ocr_images/image_5.jpg\n",
      "  Question    : What color is the main text \"故事\" on the image?\n",
      "  Answer      : The main text \"故事\" on the image is written in red.\n",
      "----------------------------------------\n",
      "task_14:\n",
      "  Image Path  : ./ocr_images/image_5.jpg\n",
      "  Question    : What is the large object on the right half of the image?\n",
      "  Answer      : The large object on the right half of the image is a smartphone.\n",
      "----------------------------------------\n",
      "task_15:\n",
      "  Image Path  : ./ocr_images/image_5.jpg\n",
      "  Question    : What natural phenomenon appears in the background of the image?\n",
      "  Answer      : The natural phenomenon appearing in the background of the image is a sunset.\n",
      "----------------------------------------\n",
      "task_16:\n",
      "  Image Path  : ./ocr_images/image_6.jpg\n",
      "  Question    : What color is the cake on the table?\n",
      "  Answer      : The cake on the table is white with what appears to be a chocolate or brown base.\n",
      "----------------------------------------\n",
      "task_17:\n",
      "  Image Path  : ./ocr_images/image_6.jpg\n",
      "  Question    : How many balloons are visible in the image?\n",
      "  Answer      : There are four balloons visible in the background of the image.\n",
      "----------------------------------------\n",
      "task_18:\n",
      "  Image Path  : ./ocr_images/image_6.jpg\n",
      "  Question    : Which character is wearing a patterned outfit?\n",
      "  Answer      : The girl next to the boy with the cake is wearing a patterned outfit with pink flowers on it.\n",
      "----------------------------------------\n",
      "task_19:\n",
      "  Image Path  : ./ocr_images/image_6.jpg\n",
      "  Question    : What is the nurse doing in the image?\n",
      "  Answer      : The nurse is applying an ice pack to the boy's forehead.\n",
      "----------------------------------------\n",
      "task_20:\n",
      "  Image Path  : ./ocr_images/image_6.jpg\n",
      "  Question    : What is the emotion of the boy blowing a candle?\n",
      "  Answer      : The emotion of the boy blowing the candle appears to be happiness as he is smiling with his eyes closed in a gesture that typically indicates a wish being made.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = \"./ocr_QA.csv\"\n",
    "images_folder_path = \"./ocr_images\"\n",
    "\n",
    "tasks = load_smmu_tasks(csv_file_path, images_folder_path)\n",
    "\n",
    "# Print each task in an organized way\n",
    "for i, task in enumerate(tasks, start=1):\n",
    "    print(f\"{task['task_id']}:\")\n",
    "    print(f\"  Image Path  : {task['image_path']}\")\n",
    "    print(f\"  Question    : {task['question']}\")\n",
    "    print(f\"  Answer      : {task['answer']}\")\n",
    "    print(\"-\" * 40)  # Divider between tasks for clarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3913328d-67f5-4dea-87f0-bfe65f2fa683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_answer(task):\n",
    "    \"\"\"\n",
    "    Generate an answer for the given task using a model. This is a placeholder function.\n",
    "    Replace this code with actual model inference logic to produce meaningful answers.\n",
    "\n",
    "    Parameters:\n",
    "    task (dict): A dictionary containing information for a specific task, such as the question and options.\n",
    "\n",
    "    Returns:\n",
    "    str: The answer generated by the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Placeholder logic for model inference\n",
    "    # Replace the following line with actual inference code for your model\n",
    "    # For example, use a model prediction based on `question` and `options`\n",
    "    model_answer = \"Simulated model answer for testing.\"  # Replace this line\n",
    "    \n",
    "    return model_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f7f725d-0b96-4b0b-a834-d7f7a1528e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert evaluator specializing in assessing questions in primary school to high school exams. I will give you a question, the expected correct answer, and a test-taker's response to the question.\n",
    "You need to analyse the given question,compare the standard answer with the provided response, and fill in the following values:\n",
    "- analysis: If the answer is incorrect, you need to give a reason for the error. If the answer is correct, you can leave it blank. The analysis must be a string, not exceeding 500 characters.\n",
    "- correct: Whether the answer to the question is correct and have necessary info. Return 1 for correct, 0 for incorrect.\n",
    "The above values should be returned in JSON format. I should be able to directly load the return value into a dict variable using the json.loads function in Python.\n",
    "\n",
    "Remember, your output should only contain the following format:\n",
    "{\n",
    "\"analysis\":,\n",
    "\"correct\":\n",
    "}\n",
    "Be sure to use double backslashes if necessary, not single backslashe. \n",
    "\"\"\"\n",
    "\n",
    "EVALUATION_USER_TEMPLATE = \"\"\"\n",
    "Here is the question:\n",
    "\"{}\"\n",
    "\n",
    "The expected correct answer to this problem:\n",
    "\"{}\"\n",
    "\n",
    "Response to the problem:\n",
    "\"{}\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb86b2f3-1799-4cd7-b052-8c4b93e4910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def gpt4_judge(reference_answer, model_answer, question):\n",
    "    # Construct the prompt for the model\n",
    "    prompt = (EVALUATION_USER_TEMPLATE.format(reference_answer, model_answer, question))\n",
    "    \n",
    "    # Make sure you're using the chat completions endpoint for GPT-4\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": EVALUATION_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=640,\n",
    "        top_p=1\n",
    "    )\n",
    "    judgement = response.choices[0].message.content.strip()\n",
    "    \n",
    "    try:\n",
    "        judgement_json = json.loads(judgement)\n",
    "        correct_value = judgement_json.get(\"correct\", 0)\n",
    "        analysis = judgement_json.get(\"analysis\", \"No analysis available\")\n",
    "        return correct_value, analysis\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing summary as JSON: {e}\")\n",
    "        return 0, \"Error in analysis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad6d7170-1096-450c-bdaa-3cdb9963e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(filename=\"evaluation.log\", level=logging.INFO)\n",
    "\n",
    "def evaluate_smmu_task(task_id, task, repetitions=3):\n",
    "    results = []\n",
    "    correct_count = 0  # Track the number of correct responses\n",
    "    total_count = repetitions\n",
    "    \n",
    "    for i in range(repetitions):\n",
    "        # Generate the model's response\n",
    "        model_answer = generate_model_answer(task)  # Replace with actual model function\n",
    "        \n",
    "        # Use the GPT-4 model to judge the answer\n",
    "        judgement,analysis = gpt4_judge(task[\"answer\"], model_answer, task[\"question\"])\n",
    "        \n",
    "        # Calculate correctness\n",
    "        correct = 1 if judgement else 0\n",
    "        correct_count += correct\n",
    "\n",
    "        # Save the results to CSV\n",
    "        save_results_to_csv(task[\"task_id\"], task[\"question\"], task[\"answer\"], model_answer, correct, analysis, output_csv)\n",
    "\n",
    "        # Log each judgement result\n",
    "        logging.info(f\"Task {task_id}, Run {i}, Judgement: {judgement}, Analysis: {analysis}\")\n",
    "\n",
    "        # Store results for further use\n",
    "        results.append({\"run\": i, \"model_answer\": model_answer, \"judgement\": judgement, \"analysis\": analysis})\n",
    "       \n",
    "    # Calculate accuracy and log it\n",
    "    accuracy = correct_count / total_count\n",
    "    logging.info(f\"Task {task_id} Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6cf4e2c-fc9c-46e5-ae6e-6778874e307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the CSV file with headers\n",
    "output_csv = \"evaluation_results.csv\"\n",
    "with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"task_id\", \"question\", \"answer\", \"response\", \"correctness\", \"analysis\"])\n",
    "\n",
    "def save_results_to_csv(task_id, question, answer, response, correctness, analysis, output_csv):\n",
    "    with open(output_csv, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([task_id, question, answer, response, correctness, analysis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8201520-4e55-4ddd-9215-c52c27b97c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    csv_file_path = \"./ocr_QA.csv\"\n",
    "    images_folder_path = \"./ocr_images\"\n",
    "    \n",
    "    # Load tasks\n",
    "    tasks = load_smmu_tasks(csv_file_path, images_folder_path)\n",
    "    \n",
    "    # Dictionary to hold all results\n",
    "    all_results = {}\n",
    "    \n",
    "    # Loop over tasks and evaluate\n",
    "    for task_id, task in enumerate(tasks):  # Corrected loop\n",
    "        task_results = evaluate_smmu_task(task_id, task, repetitions=3)  # Example with 3 repetitions\n",
    "        all_results[task_id] = task_results\n",
    "    print(\"Evaluation complete. Results saved to results.json and results.csv.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b54dd9-986e-4220-bf21-a808343c08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example analysis to get success rate per task\n",
    "results_df = pd.read_csv(\"evaluation_results.csv\")\n",
    "success_rate = results_df.groupby(\"task_id\")[\"correctness\"].apply(lambda x: sum(x == \"1\") / len(x))\n",
    "print(success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efc429-a227-41aa-b936-80b485a65cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caa97c9-a249-4121-8342-4c6461f16b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
