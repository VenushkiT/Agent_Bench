**AutoGenBench Replication: Benchmarking AI Agents**

This project replicates the functionality of AutoGenBench, a command-line tool designed to benchmark AI agents. AutoGenBench automates the process of downloading datasets, configuring agents, running evaluations, and reporting results. It also captures comprehensive logs and telemetry to aid debugging, profiling, and metric computation.

Features

1. Automated Benchmarking: Automatically download datasets, set up agents, and run evaluations.
2. Comprehensive Reporting: Generate performance reports and logs for each run, including key metrics and debugging information.
3. Telemetry and Profiling: Capture detailed logs for agent execution, profiling resource usage, and response times.
4. Custom Metrics: Define and compute custom evaluation metrics to assess agent performance in more depth.
5. AgentEval Integration: Seamless integration with AgentEval for detailed agent performance evaluation.
6. Agent Flexibility: Supports various types of agents, including reinforcement learning agents, large language models, and others.
